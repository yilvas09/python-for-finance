{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Processing\n",
    "\n",
    "Multi processing is the ability to **asynchronously execute** several tasks at once in your cpu. Moreover, if your CPU contains several cores we can also **use multiple cores** asynchronously to speed up your code.\n",
    "\n",
    "\n",
    "# Multi Processing vs. Multi Threading\n",
    "\n",
    "This is the most common source of confusion when dealing with parallel computing, so we will try to shed some light on this"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Threading\n",
    "\n",
    "In simple words, a thread is a sequence of such instructions within a program that can be executed independently of other code. For simplicity, you can assume that a thread is simply a subset of a process!\n",
    "\n",
    "Numpy standard library offers a multithreading module. We note that different threads are not necessarilly executed in different CPU cores!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of process running main program: 64474\n",
      "Main thread name: MainThread\n",
      "Task 1 assigned to thread: t1\n",
      "ID of process running task 1: 64474\n",
      "Task 2 assigned to thread: t2\n",
      "ID of process running task 2: 64474\n",
      "All has ended.\n",
      "Task 2 ends.\n",
      "Task 1 ends.\n",
      "All has ended.\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "import os \n",
    "import time\n",
    "  \n",
    "def task1(): \n",
    "    print(\"Task 1 assigned to thread: {}\".format(threading.current_thread().name)) \n",
    "    print(\"ID of process running task 1: {}\".format(os.getpid())) \n",
    "    time.sleep(5)\n",
    "    print(\"Task 1 ends.\")\n",
    "  \n",
    "def task2(): \n",
    "    print(\"Task 2 assigned to thread: {}\".format(threading.current_thread().name)) \n",
    "    print(\"ID of process running task 2: {}\".format(os.getpid())) \n",
    "    time.sleep(3)\n",
    "    print(\"Task 2 ends.\")\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "  \n",
    "    # print ID of current process \n",
    "    print(\"ID of process running main program: {}\".format(os.getpid())) \n",
    "  \n",
    "    # print name of main thread \n",
    "    print(\"Main thread name: {}\".format(threading.current_thread().name)) \n",
    "  \n",
    "    # creating threads \n",
    "    t1 = threading.Thread(target=task1, name='t1') \n",
    "    t2 = threading.Thread(target=task2, name='t2')   \n",
    "  \n",
    "    # starting threads \n",
    "    t1.start() \n",
    "    t2.start() \n",
    "    \n",
    "    print(\"All has ended.\")\n",
    "    # wait until all threads finish \n",
    "    t1.join() \n",
    "    t2.join() \n",
    "\n",
    "    print(\"All has ended.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating threads doesn't mean we want to execute that thread immediately. We are just annoucing what needs to be done. It doesn't start until `start()`.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program above runs two threads in the same process i.e. the same core"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is then multi-threading useful?\n",
    "\n",
    "Multi threading is useful for I/O bound operations like downloading data or pushing data to a database. This operations require the interpreter to wait until either the download or the database update is executed. By creating multiple threads we can, instead of waiting have multiple downloads simultaneously or execute more updates while waiting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some remarks on multi threading\n",
    "\n",
    "As threads are run in the same CPU core and environment, we need to be **careful to protect global variables** -> use thread lock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x = 200000\n",
      "Iteration 1: x = 200000\n",
      "Iteration 2: x = 200000\n",
      "Iteration 3: x = 200000\n",
      "Iteration 4: x = 163886\n",
      "Iteration 5: x = 200000\n",
      "Iteration 6: x = 200000\n",
      "Iteration 7: x = 177233\n",
      "Iteration 8: x = 200000\n",
      "Iteration 9: x = 177718\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "  \n",
    "# global variable x \n",
    "# x = 0\n",
    "  \n",
    "def increment(): \n",
    "    \"\"\" \n",
    "    function to increment global variable x \n",
    "    \"\"\"\n",
    "    global x \n",
    "    x += 1\n",
    "  \n",
    "def thread_task(): \n",
    "    \"\"\" \n",
    "    task for thread \n",
    "    calls increment function 100000 times. \n",
    "    \"\"\"\n",
    "    for _ in range(100000): \n",
    "        increment() \n",
    "  \n",
    "def main_task(): \n",
    "    global x \n",
    "    # setting global variable x as 0 \n",
    "    x = 0\n",
    "  \n",
    "    # creating threads \n",
    "    t1 = threading.Thread(target=thread_task) \n",
    "    t2 = threading.Thread(target=thread_task) \n",
    "  \n",
    "    # start threads \n",
    "    t1.start() \n",
    "    t2.start() \n",
    "  \n",
    "    # wait until threads finish their job (join this target thread to the main thread)\n",
    "    t1.join() \n",
    "    t2.join() \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    for i in range(10): \n",
    "        main_task() \n",
    "        print(\"Iteration {0}: x = {1}\".format(i,x)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As both threads are accessing the global variable $x$ we have no way to ensure that the output will be as expected since the interpreter decides in which order the actions within threads will be executed. This is known as race condition.\n",
    "\n",
    "**WHAT HAPPENS? The registers of 2 threads read the same value from the same position in RAM, add one to the value in the register, and then write exactly the same added value to the original position.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread lock\n",
    "One way to protect our code is to create a lock, and pass it as an argument when defining tasks in thread. A lock essentially makes sure that a locked piece of code is **only accessed by one thread at a time until is fully executed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x = 200000\n",
      "Iteration 1: x = 200000\n",
      "Iteration 2: x = 200000\n",
      "Iteration 3: x = 200000\n",
      "Iteration 4: x = 200000\n",
      "Iteration 5: x = 200000\n",
      "Iteration 6: x = 200000\n",
      "Iteration 7: x = 200000\n",
      "Iteration 8: x = 200000\n",
      "Iteration 9: x = 200000\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "  \n",
    "# global variable x \n",
    "x = 0\n",
    "  \n",
    "def increment(): \n",
    "    \"\"\" \n",
    "    function to increment global variable x \n",
    "    \"\"\"\n",
    "    global x \n",
    "    x += 1\n",
    "  \n",
    "def thread_task(lock): \n",
    "    \"\"\" \n",
    "    task for thread \n",
    "    calls increment function 100000 times. \n",
    "    \"\"\"\n",
    "    for _ in range(100000):\n",
    "        ########################################################################################\n",
    "        ###### The piece of code below is locked and can only be accessed when thread at a time#\n",
    "        ########################################################################################\n",
    "        lock.acquire() \n",
    "        increment() \n",
    "        lock.release() \n",
    "  \n",
    "def main_task(): \n",
    "    global x \n",
    "    # setting global variable x as 0 \n",
    "    x = 0\n",
    "  \n",
    "    # creating a lock \n",
    "    lock = threading.Lock() \n",
    "  \n",
    "    # creating threads \n",
    "    t1 = threading.Thread(target=thread_task, args=(lock,)) \n",
    "    t2 = threading.Thread(target=thread_task, args=(lock,)) \n",
    "  \n",
    "    # start threads \n",
    "    t1.start() \n",
    "    t2.start() \n",
    "  \n",
    "    # wait until threads finish their job \n",
    "    t1.join() \n",
    "    t2.join() \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    for i in range(10): \n",
    "        main_task() \n",
    "        print(\"Iteration {0}: x = {1}\".format(i,x)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread pools\n",
    "\n",
    "Obviously **manually creating threads one at a time is not very efficient**. Luckily, Python offers a threadpool library which provides a systematic way of creating as many threads as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0Processing 1\n",
      "\n",
      "Processing 2\n",
      "Processing 3\n",
      "Processing 4\n",
      "Processing 5\n",
      "Processing 6\n",
      "Processing 7\n",
      "Processing 8\n",
      "Processing 9\n",
      "Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "Processing 13\n",
      "Processing 14\n",
      "Processing 15\n",
      "Processing 16\n",
      "Processing 17\n",
      "Processing 18\n",
      "Processing 19\n",
      "My result list [3, 17, 16, 9, 8, 0, 7, 14, 5, 13, 15, 1, 12, 2, 11, 19, 4, 6, 18, 10]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "def task(n):\n",
    "    print(\"Processing {}\".format(n))\n",
    "    return n\n",
    "\n",
    "number_of_threads = 8\n",
    "pool = ThreadPoolExecutor(number_of_threads)\n",
    "\n",
    "\n",
    "futures=[]\n",
    "### We sumbit to the Threadpool all the tasks we want to perform\n",
    "for i in range(20): \n",
    "    futures.append(pool.submit(task,i)) #Syntax is pool.submit(function,args)\n",
    "results=[]\n",
    "\n",
    "### As threads are completed we collect the results\n",
    "for F in concurrent.futures.as_completed(futures):\n",
    "    results.append(F.result())\n",
    "    \n",
    "\n",
    "pool.shutdown(wait=True)\n",
    "print(\"My result list\",results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the interpreter optimises thread execution we have no control over the order of the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a similar code using .map() functionality which will also make sure that the results is presented to us in the same order that was submited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "Processing 1Processing 2\n",
      "\n",
      "Processing 3\n",
      "Processing 4\n",
      "Processing 5Processing 6\n",
      "\n",
      "Processing 7\n",
      "Processing 8Processing 9Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "Processing 13Processing 14\n",
      "\n",
      "\n",
      "\n",
      "<generator object Executor.map.<locals>.result_iterator at 0x7f06f03c22b0>\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "pool = ThreadPoolExecutor(number_of_threads)\n",
    "\n",
    "results=pool.map(task,range(15))\n",
    "\n",
    "pool.shutdown(wait=True)\n",
    "print(results)\n",
    "for value in results:\n",
    "    print(value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A practical example with improved performance using multi-threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running without threads:\n",
      "https://en.wikipedia.org/wiki/0 - exists\n",
      "https://en.wikipedia.org/wiki/1 - exists\n",
      "https://en.wikipedia.org/wiki/2 - exists\n",
      "https://en.wikipedia.org/wiki/3 - exists\n",
      "https://en.wikipedia.org/wiki/4 - exists\n",
      "https://en.wikipedia.org/wiki/5 - exists\n",
      "https://en.wikipedia.org/wiki/6 - exists\n",
      "https://en.wikipedia.org/wiki/7 - exists\n",
      "https://en.wikipedia.org/wiki/8 - exists\n",
      "https://en.wikipedia.org/wiki/9 - exists\n",
      "https://en.wikipedia.org/wiki/10 - exists\n",
      "https://en.wikipedia.org/wiki/11 - exists\n",
      "https://en.wikipedia.org/wiki/12 - exists\n",
      "https://en.wikipedia.org/wiki/13 - exists\n",
      "https://en.wikipedia.org/wiki/14 - exists\n",
      "https://en.wikipedia.org/wiki/15 - exists\n",
      "https://en.wikipedia.org/wiki/16 - exists\n",
      "https://en.wikipedia.org/wiki/17 - exists\n",
      "https://en.wikipedia.org/wiki/18 - exists\n",
      "https://en.wikipedia.org/wiki/19 - exists\n",
      "https://en.wikipedia.org/wiki/20 - exists\n",
      "https://en.wikipedia.org/wiki/21 - exists\n",
      "https://en.wikipedia.org/wiki/22 - exists\n",
      "https://en.wikipedia.org/wiki/23 - exists\n",
      "https://en.wikipedia.org/wiki/24 - exists\n",
      "https://en.wikipedia.org/wiki/25 - exists\n",
      "https://en.wikipedia.org/wiki/26 - exists\n",
      "https://en.wikipedia.org/wiki/27 - exists\n",
      "https://en.wikipedia.org/wiki/28 - exists\n",
      "https://en.wikipedia.org/wiki/29 - exists\n",
      "https://en.wikipedia.org/wiki/30 - exists\n",
      "https://en.wikipedia.org/wiki/31 - exists\n",
      "https://en.wikipedia.org/wiki/32 - exists\n",
      "https://en.wikipedia.org/wiki/33 - exists\n",
      "https://en.wikipedia.org/wiki/34 - exists\n",
      "https://en.wikipedia.org/wiki/35 - exists\n",
      "https://en.wikipedia.org/wiki/36 - exists\n",
      "https://en.wikipedia.org/wiki/37 - exists\n",
      "https://en.wikipedia.org/wiki/38 - exists\n",
      "https://en.wikipedia.org/wiki/39 - exists\n",
      "https://en.wikipedia.org/wiki/40 - exists\n",
      "https://en.wikipedia.org/wiki/41 - exists\n",
      "https://en.wikipedia.org/wiki/42 - exists\n",
      "https://en.wikipedia.org/wiki/43 - exists\n",
      "https://en.wikipedia.org/wiki/44 - exists\n",
      "https://en.wikipedia.org/wiki/45 - exists\n",
      "https://en.wikipedia.org/wiki/46 - exists\n",
      "https://en.wikipedia.org/wiki/47 - exists\n",
      "https://en.wikipedia.org/wiki/48 - exists\n",
      "https://en.wikipedia.org/wiki/49 - exists\n",
      "Without threads time: 20.12255859375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "def get_wiki_page_existence(wiki_page_url, timeout=10):\n",
    "    response = requests.get(url=wiki_page_url, timeout=timeout)\n",
    "\n",
    "    page_status = \"unknown\"\n",
    "    if response.status_code == 200:\n",
    "        page_status = \"exists\"\n",
    "    elif response.status_code == 404:\n",
    "        page_status = \"does not exist\"\n",
    "\n",
    "    return wiki_page_url + \" - \" + page_status\n",
    "\n",
    "wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n",
    "\n",
    "print(\"Running without threads:\")\n",
    "without_threads_start = time.time()\n",
    "for url in wiki_page_urls:\n",
    "    print(get_wiki_page_existence(wiki_page_url=url))\n",
    "print(\"Without threads time:\", time.time() - without_threads_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running threaded 1:\n",
      "Threaded time: 7.253835916519165\n",
      "Running threaded 2:\n",
      "https://en.wikipedia.org/wiki/3 - exists\n",
      "https://en.wikipedia.org/wiki/7 - exists\n",
      "https://en.wikipedia.org/wiki/2 - exists\n",
      "https://en.wikipedia.org/wiki/1 - exists\n",
      "https://en.wikipedia.org/wiki/0 - exists\n",
      "https://en.wikipedia.org/wiki/4 - exists\n",
      "https://en.wikipedia.org/wiki/10 - exists\n",
      "https://en.wikipedia.org/wiki/5 - exists\n",
      "https://en.wikipedia.org/wiki/11 - exists\n",
      "https://en.wikipedia.org/wiki/13 - exists\n",
      "https://en.wikipedia.org/wiki/8 - exists\n",
      "https://en.wikipedia.org/wiki/14 - exists\n",
      "https://en.wikipedia.org/wiki/12 - exists\n",
      "https://en.wikipedia.org/wiki/9 - exists\n",
      "https://en.wikipedia.org/wiki/20 - exists\n",
      "https://en.wikipedia.org/wiki/21 - exists\n",
      "https://en.wikipedia.org/wiki/6 - exists\n",
      "https://en.wikipedia.org/wiki/22 - exists\n",
      "https://en.wikipedia.org/wiki/17 - exists\n",
      "https://en.wikipedia.org/wiki/23 - exists\n",
      "https://en.wikipedia.org/wiki/24 - exists\n",
      "https://en.wikipedia.org/wiki/25 - exists\n",
      "https://en.wikipedia.org/wiki/26 - exists\n",
      "https://en.wikipedia.org/wiki/16 - exists\n",
      "https://en.wikipedia.org/wiki/27 - exists\n",
      "https://en.wikipedia.org/wiki/28 - exists\n",
      "https://en.wikipedia.org/wiki/29 - exists\n",
      "https://en.wikipedia.org/wiki/18 - exists\n",
      "https://en.wikipedia.org/wiki/30 - exists\n",
      "https://en.wikipedia.org/wiki/31 - exists\n",
      "https://en.wikipedia.org/wiki/15 - exists\n",
      "https://en.wikipedia.org/wiki/19 - exists\n",
      "https://en.wikipedia.org/wiki/32 - exists\n",
      "https://en.wikipedia.org/wiki/33 - exists\n",
      "https://en.wikipedia.org/wiki/35 - exists\n",
      "https://en.wikipedia.org/wiki/34 - exists\n",
      "https://en.wikipedia.org/wiki/36 - exists\n",
      "https://en.wikipedia.org/wiki/37 - exists\n",
      "https://en.wikipedia.org/wiki/38 - exists\n",
      "https://en.wikipedia.org/wiki/39 - exists\n",
      "https://en.wikipedia.org/wiki/41 - exists\n",
      "https://en.wikipedia.org/wiki/40 - exists\n",
      "https://en.wikipedia.org/wiki/44 - exists\n",
      "https://en.wikipedia.org/wiki/46 - exists\n",
      "https://en.wikipedia.org/wiki/48 - exists\n",
      "https://en.wikipedia.org/wiki/47 - exists\n",
      "https://en.wikipedia.org/wiki/49 - exists\n",
      "https://en.wikipedia.org/wiki/43 - exists\n",
      "https://en.wikipedia.org/wiki/42 - exists\n",
      "https://en.wikipedia.org/wiki/45 - exists\n",
      "Threaded time: 6.56489109992981\n"
     ]
    }
   ],
   "source": [
    "def get_wiki_page_existence(wiki_page_url, timeout=10):\n",
    "    response = requests.get(url=wiki_page_url, timeout=timeout)\n",
    "\n",
    "    page_status = \"unknown\"\n",
    "    if response.status_code == 200:\n",
    "        page_status = \"exists\"\n",
    "    elif response.status_code == 404:\n",
    "        page_status = \"does not exist\"\n",
    "\n",
    "    return wiki_page_url + \" - \" + page_status\n",
    "wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n",
    "\n",
    "print(\"Running threaded 1:\")\n",
    "threaded_start = time.time()\n",
    "number_of_threads=8\n",
    "pool = ThreadPoolExecutor(number_of_threads)\n",
    "\n",
    "\n",
    "pool.map(get_wiki_page_existence,wiki_page_urls)\n",
    "pool.shutdown(wait=True)\n",
    "\n",
    "print(\"Threaded time:\", time.time() - threaded_start)\n",
    "\n",
    "#####################\n",
    "\n",
    "print(\"Running threaded 2:\")\n",
    "threaded_start = time.time()\n",
    "pool = ThreadPoolExecutor(number_of_threads)\n",
    "futures = []\n",
    "for url in wiki_page_urls:\n",
    "    futures.append(pool.submit(get_wiki_page_existence, wiki_page_url=url))\n",
    "for future in concurrent.futures.as_completed(futures):\n",
    "    print(future.result())\n",
    "pool.shutdown(wait=True)\n",
    "\n",
    "print(\"Threaded time:\", time.time() - threaded_start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing\n",
    "\n",
    "In simple words, multiprocessing refers to the ability of a system to support more than one processor at the same time. Applications in a multiprocessing system are broken to smaller routines that run independently. The operating system allocates these threads to the processors improving performance of the system.\n",
    "\n",
    "A multiprocessing system can have:\n",
    "\n",
    "1. multiprocessor, i.e. a computer with more than one central processor.\n",
    "2. multi-core processor, i.e. a single computing component with two or more independent actual processing units (called “cores”).\n",
    "\n",
    "Here, the CPU can easily executes several tasks **at once**, with each task **using its own processor**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucky for us Python's standard package includes a multiprocessing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of main process: 64474\n",
      "ID of process p1: 64956\n",
      "ID of process p2: 64957\n",
      "Both processes finished execution!\n",
      "Process p1 is alive: False\n",
      "Process p2 is alive: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker2' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker1' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing \n",
    "import os \n",
    "  \n",
    "def worker1(): \n",
    "    # printing process id \n",
    "    print(\"ID of process running worker1: {}\".format(os.getpid())) \n",
    "  \n",
    "def worker2(): \n",
    "    # printing process id \n",
    "    print(\"ID of process running worker2: {}\".format(os.getpid())) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    # printing main program process id \n",
    "    print(\"ID of main process: {}\".format(os.getpid())) \n",
    "  \n",
    "    # creating processes \n",
    "    p1 = multiprocessing.Process(target=worker1) \n",
    "    p2 = multiprocessing.Process(target=worker2) \n",
    "  \n",
    "    # starting processes \n",
    "    p1.start() \n",
    "    p2.start() \n",
    "  \n",
    "    # process IDs \n",
    "    print(\"ID of process p1: {}\".format(p1.pid)) \n",
    "    print(\"ID of process p2: {}\".format(p2.pid)) \n",
    "  \n",
    "    # wait until processes are finished \n",
    "    p1.join() \n",
    "    p2.join() \n",
    "  \n",
    "    # both processes finished \n",
    "    print(\"Both processes finished execution!\") \n",
    "  \n",
    "    # check if processes are alive \n",
    "    print(\"Process p1 is alive: {}\".format(p1.is_alive())) \n",
    "    print(\"Process p2 is alive: {}\".format(p2.is_alive())) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see now each process gets a different ID, meaning it is executed at a different core. Moreover, multiprocessing in Python means that each process will run with a independent GIL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queues\n",
    "\n",
    "Typically on a multi processing task we have a **number of jobs to do**, which could potentially be **larger than the number of cores available** in the computer. We use queues to pile the number of jobs to do and **dispatch them on a first in first out (FIFO) basis**. Most importantly queues are thread-safe meaning that only one process can access the queue at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = multiprocessing.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.queues.Queue at 0x10712f910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.put(\"hello\")\n",
    "queue.put(\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'worker' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "def worker(queue):\n",
    "    while not queue.empty():\n",
    "        print(\"Process \"+str(os.getpid())+\"received: \" + str(queue.get()))\n",
    "    \n",
    "\n",
    "    \n",
    "queue = multiprocessing.Queue()\n",
    "\n",
    "for i in range(20):\n",
    "    queue.put(i)\n",
    "num_processes=4\n",
    "processes=[]\n",
    "for _ in range(num_processes):\n",
    "    p=multiprocessing.Process(target=worker, args=[queue])\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "\n",
    "\n",
    "for pr in processes:\n",
    "    pr.join()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process pools\n",
    "\n",
    "Similar to threadpools we can use process pools with exactl the same user case as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'task' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'task' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m###As threads are completed we collect the results\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m F \u001b[39min\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mas_completed(futures):\n\u001b[0;32m---> 21\u001b[0m     results\u001b[39m.\u001b[39mappend(F\u001b[39m.\u001b[39mresult())\n\u001b[1;32m     24\u001b[0m pool\u001b[39m.\u001b[39mshutdown(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMy result list\u001b[39m\u001b[39m\"\u001b[39m,results)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    437\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 438\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "\n",
    "def task(n):\n",
    "    print(\"Processing {}\".format(n))\n",
    "    return n\n",
    "\n",
    "number_of_threads=4\n",
    "pool = ProcessPoolExecutor(number_of_threads)\n",
    "\n",
    "\n",
    "futures=[]\n",
    "### We sumbit to the Threadpool all the tasks we want to perform\n",
    "for i in range(20): \n",
    "    futures.append(pool.submit(task,i)) #Syntax is pool.submit(function,args)\n",
    "results=[]\n",
    "\n",
    "###As threads are completed we collect the results\n",
    "for F in concurrent.futures.as_completed(futures):\n",
    "    results.append(F.result())\n",
    "    \n",
    "\n",
    "pool.shutdown(wait=True)\n",
    "print(\"My result list\",results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi processing and random numbers\n",
    "\n",
    "One needs to be careful with random number generation and multi processing, as **we could be using the same random number twice, because the generating seed actually follows a deterministic sequence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Foo_np' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-18:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Foo_np' on <module '__main__' (built-in)>\n",
      "Process SpawnProcess-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py\", line 237, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'Foo_np' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m results\u001b[39m=\u001b[39mpool\u001b[39m.\u001b[39mmap(Foo_np, \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/process.py:559\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    554\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 559\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    560\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    561\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:608\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    606\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    607\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 608\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39;49mpop()\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    609\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39mpop()\u001b[39m.\u001b[39mresult(end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:445\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    444\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 445\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    446\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "number_of_threads=4\n",
    "pool = ProcessPoolExecutor(number_of_threads)\n",
    "\n",
    "def Foo_np(seed=None):\n",
    "    return np.random.uniform(0, 1)\n",
    "\n",
    "results=pool.map(Foo_np, range(20))\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One needs to provide the random seed explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5488135]\n",
      "[0.417022]\n",
      "[0.4359949]\n",
      "[0.5507979]\n",
      "[0.96702984]\n",
      "[0.22199317]\n",
      "[0.89286015]\n",
      "[0.07630829]\n",
      "[0.8734294]\n",
      "[0.01037415]\n",
      "[0.77132064]\n",
      "[0.18026969]\n",
      "[0.15416284]\n",
      "[0.77770241]\n",
      "[0.51394334]\n",
      "[0.8488177]\n",
      "[0.22329108]\n",
      "[0.294665]\n",
      "[0.65037424]\n",
      "[0.0975336]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "number_of_threads=4\n",
    "pool = ProcessPoolExecutor(number_of_threads)\n",
    "\n",
    "def Foo_np(seed=None):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.uniform(0, 1, 1)\n",
    "\n",
    "results=pool.map(Foo_np, range(20))\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple Monte Carlo example: computing Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pi_python(num_sim,seed):\n",
    "    np.random.seed(seed)\n",
    "    x=2.0*(np.random.random(size=num_sim)-0.5)# np.random.random returns U[0,1] so we reescale it to U[-1,1]\n",
    "    y=2.0*(np.random.random(size=num_sim)-0.5)\n",
    "\n",
    "    inside=np.sum(x*x+y*y<=1)\n",
    "    \n",
    "    \n",
    "    pi=inside/num_sim*4\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim=10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 ms ± 125 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_pi_python(num_sim,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14129"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_pi_python(num_sim,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "number_of_threads=4 \n",
    "def parallel_compute_pi_python(number_of_threads,num_sim):\n",
    "    pool = ProcessPoolExecutor(number_of_threads)\n",
    "\n",
    "\n",
    "    results=pool.map(compute_pi_python,[int(num_sim/number_of_threads)]*number_of_threads, range(number_of_threads))\n",
    "    MC_mean=0\n",
    "    for result in results:\n",
    "        MC_mean+=result\n",
    "    return MC_mean/number_of_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1413320000000002"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_compute_pi_python(4,num_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 8.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit parallel_compute_pi_python(4,num_sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "\n",
    "1. For multithreading to start to be noticeable the Monte Carlo simulation needs to be heavy as setting up the process pool adds overhead\n",
    "\n",
    "2. We have made the oversimplication of changing the random seed arbitrarily in each process. This could cause that a sequence of random variables could be repeated accross processes and generate correlation. For the single process and multi-process approach to agree on the estimate one would need to set the correct seed on each process. This topic is outside the scope of this course, but one needs to be very careful with this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
