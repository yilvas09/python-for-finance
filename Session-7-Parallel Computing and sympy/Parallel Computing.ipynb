{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Processing\n",
    "\n",
    "### Multi processing is the ability to asynchronously execute several tasks at once in your cpu. Moreover, if your CPU contains several cores we can also use multiple cores asynchronously to speed up your code.\n",
    "\n",
    "\n",
    "# Multi Processing vs. Multi Threading\n",
    "\n",
    "### This is the most common source of confusion when dealing with parallel computing, so we will try to shed some light on this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Threading\n",
    "\n",
    "### In simple words, a thread is a sequence of such instructions within a program that can be executed independently of other code. For simplicity, you can assume that a thread is simply a subset of a process!\n",
    "\n",
    "### Numpy standard library offers a multithreading module. We note that different threads are not necessarilly executed in different CPU cores!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of process running main program: 6661\n",
      "Main thread name: MainThread\n",
      "Task 1 assigned to thread: t1\n",
      "ID of process running task 1: 6661\n",
      "Task 2 assigned to thread: t2\n",
      "ID of process running task 2: 6661\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "import os \n",
    "  \n",
    "def task1(): \n",
    "    print(\"Task 1 assigned to thread: {}\".format(threading.current_thread().name)) \n",
    "    print(\"ID of process running task 1: {}\".format(os.getpid())) \n",
    "  \n",
    "def task2(): \n",
    "    print(\"Task 2 assigned to thread: {}\".format(threading.current_thread().name)) \n",
    "    print(\"ID of process running task 2: {}\".format(os.getpid())) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "  \n",
    "    # print ID of current process \n",
    "    print(\"ID of process running main program: {}\".format(os.getpid())) \n",
    "  \n",
    "    # print name of main thread \n",
    "    print(\"Main thread name: {}\".format(threading.current_thread().name)) \n",
    "  \n",
    "    # creating threads \n",
    "    t1 = threading.Thread(target=task1, name='t1') \n",
    "    t2 = threading.Thread(target=task2, name='t2')   \n",
    "  \n",
    "    # starting threads \n",
    "    t1.start() \n",
    "    t2.start() \n",
    "  \n",
    "    # wait until all threads finish \n",
    "    t1.join() \n",
    "    t2.join() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The program above runs two threads in the same process i.e. the same core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When is then multi-threading useful?\n",
    "\n",
    "### Multi threading is useful for I/O bound operations like downloading data or pushing data to a database. This operations require the interpreter to wait until either the download or the database update is executed. By creating multiple threads we can, instead of waiting have multiple downloads simultaneously or execute more updates while waiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some remarks on multi threading\n",
    "\n",
    "### As threads are run in the same CPU core and environment, we need to be careful to protect global variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x = 200000\n",
      "Iteration 1: x = 123526\n",
      "Iteration 2: x = 156748\n",
      "Iteration 3: x = 168165\n",
      "Iteration 4: x = 177653\n",
      "Iteration 5: x = 200000\n",
      "Iteration 6: x = 180494\n",
      "Iteration 7: x = 200000\n",
      "Iteration 8: x = 199976\n",
      "Iteration 9: x = 200000\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "  \n",
    "# global variable x \n",
    "x = 0\n",
    "  \n",
    "def increment(): \n",
    "    \"\"\" \n",
    "    function to increment global variable x \n",
    "    \"\"\"\n",
    "    global x \n",
    "    x += 1\n",
    "  \n",
    "def thread_task(): \n",
    "    \"\"\" \n",
    "    task for thread \n",
    "    calls increment function 100000 times. \n",
    "    \"\"\"\n",
    "    for _ in range(100000): \n",
    "        increment() \n",
    "  \n",
    "def main_task(): \n",
    "    global x \n",
    "    # setting global variable x as 0 \n",
    "    x = 0\n",
    "  \n",
    "    # creating threads \n",
    "    t1 = threading.Thread(target=thread_task) \n",
    "    t2 = threading.Thread(target=thread_task) \n",
    "  \n",
    "    # start threads \n",
    "    t1.start() \n",
    "    t2.start() \n",
    "  \n",
    "    # wait until threads finish their job \n",
    "    t1.join() \n",
    "    t2.join() \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    for i in range(10): \n",
    "        main_task() \n",
    "        print(\"Iteration {0}: x = {1}\".format(i,x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As both threads are accessing the global variable $x$ we have no way to ensure that the output will be as expected since the interpreter decides in which order the actions within threads will be executed. This is known as race condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thread lock\n",
    "### One way to protect our code is to use a lock. A lock essentially makes sure that a locked piece of code is only accessed by one thread at a time until is fully executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x = 200000\n",
      "Iteration 1: x = 200000\n",
      "Iteration 2: x = 200000\n",
      "Iteration 3: x = 200000\n",
      "Iteration 4: x = 200000\n",
      "Iteration 5: x = 200000\n",
      "Iteration 6: x = 200000\n",
      "Iteration 7: x = 200000\n",
      "Iteration 8: x = 200000\n",
      "Iteration 9: x = 200000\n"
     ]
    }
   ],
   "source": [
    "import threading \n",
    "  \n",
    "# global variable x \n",
    "x = 0\n",
    "  \n",
    "def increment(): \n",
    "    \"\"\" \n",
    "    function to increment global variable x \n",
    "    \"\"\"\n",
    "    global x \n",
    "    x += 1\n",
    "  \n",
    "def thread_task(lock): \n",
    "    \"\"\" \n",
    "    task for thread \n",
    "    calls increment function 100000 times. \n",
    "    \"\"\"\n",
    "    for _ in range(100000):\n",
    "        ########################################################################################\n",
    "        ###### The piece of code below is locked and can only be accessed when thread at a time#\n",
    "        ########################################################################################\n",
    "        lock.acquire() \n",
    "        increment() \n",
    "        lock.release() \n",
    "  \n",
    "def main_task(): \n",
    "    global x \n",
    "    # setting global variable x as 0 \n",
    "    x = 0\n",
    "  \n",
    "    # creating a lock \n",
    "    lock = threading.Lock() \n",
    "  \n",
    "    # creating threads \n",
    "    t1 = threading.Thread(target=thread_task, args=(lock,)) \n",
    "    t2 = threading.Thread(target=thread_task, args=(lock,)) \n",
    "  \n",
    "    # start threads \n",
    "    t1.start() \n",
    "    t2.start() \n",
    "  \n",
    "    # wait until threads finish their job \n",
    "    t1.join() \n",
    "    t2.join() \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    for i in range(10): \n",
    "        main_task() \n",
    "        print(\"Iteration {0}: x = {1}\".format(i,x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thread pools\n",
    "\n",
    "### Obviosly manually creating threads one at a time is not very efficient. Luckily, Python offers a threadpool library which provides a systematic way of creating as many threads as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "Processing 1\n",
      "Processing 2Processing 3\n",
      "\n",
      "Processing 4\n",
      "Processing 5\n",
      "Processing 6\n",
      "Processing 7\n",
      "Processing 8\n",
      "Processing 9\n",
      "Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "Processing 13\n",
      "Processing 14\n",
      "Processing 15\n",
      "Processing 16\n",
      "Processing 17\n",
      "Processing 18\n",
      "Processing 19\n",
      "My result list [2, 0, 7, 3, 6, 4, 1, 5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "def task(n):\n",
    "    print(\"Processing {}\".format(n))\n",
    "    return n\n",
    "\n",
    "number_of_threads=8\n",
    "pool = ThreadPoolExecutor(number_of_threads)\n",
    "\n",
    "\n",
    "futures=[]\n",
    "### We sumbit to the Threadpool all the tasks we want to perform\n",
    "for i in range(20): \n",
    "    futures.append(pool.submit(task,i)) #Syntax is pool.submit(function,args)\n",
    "results=[]\n",
    "\n",
    "###As threads are completed we collect the results\n",
    "for F in concurrent.futures.as_completed(futures):\n",
    "    results.append(F.result())\n",
    "    \n",
    "\n",
    "pool.shutdown(wait=True)\n",
    "print(\"My result list\",results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As the interpreter optimises thread execution we have no control over the order of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do a similar code using .map() functionality which will also make sure that the results is presented to us in the same order that was submited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "Processing 1Processing 2\n",
      "\n",
      "Processing 3\n",
      "Processing 4\n",
      "Processing 5Processing 6\n",
      "\n",
      "Processing 7\n",
      "Processing 8Processing 9Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "Processing 13Processing 14\n",
      "\n",
      "\n",
      "\n",
      "<generator object Executor.map.<locals>.result_iterator at 0x7f06f03c22b0>\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "pool = ThreadPoolExecutor(number_of_threads)\n",
    "\n",
    "results=pool.map(task,range(15))\n",
    "\n",
    "pool.shutdown(wait=True)\n",
    "print(results)\n",
    "for value in results:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A practical example with improved performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running without threads:\n",
      "https://en.wikipedia.org/wiki/0 - exists\n",
      "https://en.wikipedia.org/wiki/1 - exists\n",
      "https://en.wikipedia.org/wiki/2 - exists\n",
      "https://en.wikipedia.org/wiki/3 - exists\n",
      "https://en.wikipedia.org/wiki/4 - exists\n",
      "https://en.wikipedia.org/wiki/5 - exists\n",
      "https://en.wikipedia.org/wiki/6 - exists\n",
      "https://en.wikipedia.org/wiki/7 - exists\n",
      "https://en.wikipedia.org/wiki/8 - exists\n",
      "https://en.wikipedia.org/wiki/9 - exists\n",
      "https://en.wikipedia.org/wiki/10 - exists\n",
      "https://en.wikipedia.org/wiki/11 - exists\n",
      "https://en.wikipedia.org/wiki/12 - exists\n",
      "https://en.wikipedia.org/wiki/13 - exists\n",
      "https://en.wikipedia.org/wiki/14 - exists\n",
      "https://en.wikipedia.org/wiki/15 - exists\n",
      "https://en.wikipedia.org/wiki/16 - exists\n",
      "https://en.wikipedia.org/wiki/17 - exists\n",
      "https://en.wikipedia.org/wiki/18 - exists\n",
      "https://en.wikipedia.org/wiki/19 - exists\n",
      "https://en.wikipedia.org/wiki/20 - exists\n",
      "https://en.wikipedia.org/wiki/21 - exists\n",
      "https://en.wikipedia.org/wiki/22 - exists\n",
      "https://en.wikipedia.org/wiki/23 - exists\n",
      "https://en.wikipedia.org/wiki/24 - exists\n",
      "https://en.wikipedia.org/wiki/25 - exists\n",
      "https://en.wikipedia.org/wiki/26 - exists\n",
      "https://en.wikipedia.org/wiki/27 - exists\n",
      "https://en.wikipedia.org/wiki/28 - exists\n",
      "https://en.wikipedia.org/wiki/29 - exists\n",
      "https://en.wikipedia.org/wiki/30 - exists\n",
      "https://en.wikipedia.org/wiki/31 - exists\n",
      "https://en.wikipedia.org/wiki/32 - exists\n",
      "https://en.wikipedia.org/wiki/33 - exists\n",
      "https://en.wikipedia.org/wiki/34 - exists\n",
      "https://en.wikipedia.org/wiki/35 - exists\n",
      "https://en.wikipedia.org/wiki/36 - exists\n",
      "https://en.wikipedia.org/wiki/37 - exists\n",
      "https://en.wikipedia.org/wiki/38 - exists\n",
      "https://en.wikipedia.org/wiki/39 - exists\n",
      "https://en.wikipedia.org/wiki/40 - exists\n",
      "https://en.wikipedia.org/wiki/41 - exists\n",
      "https://en.wikipedia.org/wiki/42 - exists\n",
      "https://en.wikipedia.org/wiki/43 - exists\n",
      "https://en.wikipedia.org/wiki/44 - exists\n",
      "https://en.wikipedia.org/wiki/45 - exists\n",
      "https://en.wikipedia.org/wiki/46 - exists\n",
      "https://en.wikipedia.org/wiki/47 - exists\n",
      "https://en.wikipedia.org/wiki/48 - exists\n",
      "https://en.wikipedia.org/wiki/49 - exists\n",
      "Without threads time: 20.12255859375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import concurrent.futures\n",
    "\n",
    "\n",
    "def get_wiki_page_existence(wiki_page_url, timeout=10):\n",
    "    response = requests.get(url=wiki_page_url, timeout=timeout)\n",
    "\n",
    "    page_status = \"unknown\"\n",
    "    if response.status_code == 200:\n",
    "        page_status = \"exists\"\n",
    "    elif response.status_code == 404:\n",
    "        page_status = \"does not exist\"\n",
    "\n",
    "    return wiki_page_url + \" - \" + page_status\n",
    "\n",
    "wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n",
    "\n",
    "print(\"Running without threads:\")\n",
    "without_threads_start = time.time()\n",
    "for url in wiki_page_urls:\n",
    "    print(get_wiki_page_existence(wiki_page_url=url))\n",
    "print(\"Without threads time:\", time.time() - without_threads_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running threaded 1:\n",
      "Threaded time: 7.253835916519165\n",
      "Running threaded 2:\n",
      "https://en.wikipedia.org/wiki/3 - exists\n",
      "https://en.wikipedia.org/wiki/7 - exists\n",
      "https://en.wikipedia.org/wiki/2 - exists\n",
      "https://en.wikipedia.org/wiki/1 - exists\n",
      "https://en.wikipedia.org/wiki/0 - exists\n",
      "https://en.wikipedia.org/wiki/4 - exists\n",
      "https://en.wikipedia.org/wiki/10 - exists\n",
      "https://en.wikipedia.org/wiki/5 - exists\n",
      "https://en.wikipedia.org/wiki/11 - exists\n",
      "https://en.wikipedia.org/wiki/13 - exists\n",
      "https://en.wikipedia.org/wiki/8 - exists\n",
      "https://en.wikipedia.org/wiki/14 - exists\n",
      "https://en.wikipedia.org/wiki/12 - exists\n",
      "https://en.wikipedia.org/wiki/9 - exists\n",
      "https://en.wikipedia.org/wiki/20 - exists\n",
      "https://en.wikipedia.org/wiki/21 - exists\n",
      "https://en.wikipedia.org/wiki/6 - exists\n",
      "https://en.wikipedia.org/wiki/22 - exists\n",
      "https://en.wikipedia.org/wiki/17 - exists\n",
      "https://en.wikipedia.org/wiki/23 - exists\n",
      "https://en.wikipedia.org/wiki/24 - exists\n",
      "https://en.wikipedia.org/wiki/25 - exists\n",
      "https://en.wikipedia.org/wiki/26 - exists\n",
      "https://en.wikipedia.org/wiki/16 - exists\n",
      "https://en.wikipedia.org/wiki/27 - exists\n",
      "https://en.wikipedia.org/wiki/28 - exists\n",
      "https://en.wikipedia.org/wiki/29 - exists\n",
      "https://en.wikipedia.org/wiki/18 - exists\n",
      "https://en.wikipedia.org/wiki/30 - exists\n",
      "https://en.wikipedia.org/wiki/31 - exists\n",
      "https://en.wikipedia.org/wiki/15 - exists\n",
      "https://en.wikipedia.org/wiki/19 - exists\n",
      "https://en.wikipedia.org/wiki/32 - exists\n",
      "https://en.wikipedia.org/wiki/33 - exists\n",
      "https://en.wikipedia.org/wiki/35 - exists\n",
      "https://en.wikipedia.org/wiki/34 - exists\n",
      "https://en.wikipedia.org/wiki/36 - exists\n",
      "https://en.wikipedia.org/wiki/37 - exists\n",
      "https://en.wikipedia.org/wiki/38 - exists\n",
      "https://en.wikipedia.org/wiki/39 - exists\n",
      "https://en.wikipedia.org/wiki/41 - exists\n",
      "https://en.wikipedia.org/wiki/40 - exists\n",
      "https://en.wikipedia.org/wiki/44 - exists\n",
      "https://en.wikipedia.org/wiki/46 - exists\n",
      "https://en.wikipedia.org/wiki/48 - exists\n",
      "https://en.wikipedia.org/wiki/47 - exists\n",
      "https://en.wikipedia.org/wiki/49 - exists\n",
      "https://en.wikipedia.org/wiki/43 - exists\n",
      "https://en.wikipedia.org/wiki/42 - exists\n",
      "https://en.wikipedia.org/wiki/45 - exists\n",
      "Threaded time: 6.56489109992981\n"
     ]
    }
   ],
   "source": [
    "def get_wiki_page_existence(wiki_page_url, timeout=10):\n",
    "    response = requests.get(url=wiki_page_url, timeout=timeout)\n",
    "\n",
    "    page_status = \"unknown\"\n",
    "    if response.status_code == 200:\n",
    "        page_status = \"exists\"\n",
    "    elif response.status_code == 404:\n",
    "        page_status = \"does not exist\"\n",
    "\n",
    "    return wiki_page_url + \" - \" + page_status\n",
    "wiki_page_urls = [\"https://en.wikipedia.org/wiki/\" + str(i) for i in range(50)]\n",
    "\n",
    "print(\"Running threaded 1:\")\n",
    "threaded_start = time.time()\n",
    "number_of_threads=8\n",
    "pool = ThreadPoolExecutor(number_of_threads)\n",
    "\n",
    "\n",
    "pool.map(get_wiki_page_existence,wiki_page_urls)\n",
    "pool.shutdown(wait=True)\n",
    "\n",
    "print(\"Threaded time:\", time.time() - threaded_start)\n",
    "\n",
    "#####################\n",
    "\n",
    "print(\"Running threaded 2:\")\n",
    "threaded_start = time.time()\n",
    "pool = ThreadPoolExecutor(number_of_threads)\n",
    "futures = []\n",
    "for url in wiki_page_urls:\n",
    "    futures.append(pool.submit(get_wiki_page_existence, wiki_page_url=url))\n",
    "for future in concurrent.futures.as_completed(futures):\n",
    "    print(future.result())\n",
    "pool.shutdown(wait=True)\n",
    "\n",
    "print(\"Threaded time:\", time.time() - threaded_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Processing\n",
    "\n",
    "### In simple words, multiprocessing refers to the ability of a system to support more than one processor at the same time. Applications in a multiprocessing system are broken to smaller routines that run independently. The operating system allocates these threads to the processors improving performance of the system.\n",
    "\n",
    "### A multiprocessing system can have:\n",
    "\n",
    "### a)multiprocessor, i.e. a computer with more than one central processor.\n",
    "### b) multi-core processor, i.e. a single computing component with two or more independent actual processing units (called “cores”).\n",
    "#### Here, the CPU can easily executes several tasks at once, with each task using its own processor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lucky for us Python's standard package includes a multiprocessing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID of main process: 6661\n",
      "ID of process running worker1: 8913\n",
      "ID of process running worker2: 8914\n",
      "ID of process p1: 8913\n",
      "ID of process p2: 8914\n",
      "Both processes finished execution!\n",
      "Process p1 is alive: False\n",
      "Process p2 is alive: False\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing \n",
    "import os \n",
    "  \n",
    "def worker1(): \n",
    "    # printing process id \n",
    "    print(\"ID of process running worker1: {}\".format(os.getpid())) \n",
    "  \n",
    "def worker2(): \n",
    "    # printing process id \n",
    "    print(\"ID of process running worker2: {}\".format(os.getpid())) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    # printing main program process id \n",
    "    print(\"ID of main process: {}\".format(os.getpid())) \n",
    "  \n",
    "    # creating processes \n",
    "    p1 = multiprocessing.Process(target=worker1) \n",
    "    p2 = multiprocessing.Process(target=worker2) \n",
    "  \n",
    "    # starting processes \n",
    "    p1.start() \n",
    "    p2.start() \n",
    "  \n",
    "    # process IDs \n",
    "    print(\"ID of process p1: {}\".format(p1.pid)) \n",
    "    print(\"ID of process p2: {}\".format(p2.pid)) \n",
    "  \n",
    "    # wait until processes are finished \n",
    "    p1.join() \n",
    "    p2.join() \n",
    "  \n",
    "    # both processes finished \n",
    "    print(\"Both processes finished execution!\") \n",
    "  \n",
    "    # check if processes are alive \n",
    "    print(\"Process p1 is alive: {}\".format(p1.is_alive())) \n",
    "    print(\"Process p2 is alive: {}\".format(p2.is_alive())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see now each process gets a different ID, meaning it is executed at a different core. Moreover, multiprocessing in Python means that each process will run with a independent GIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queues\n",
    "\n",
    "### Tipically on a multi processing task we have a number of jobs to do, which could potentially be larger than the number of cores available in the computer. We use queues to pile the number of jobs to do and dispatch them on a first in first out (FIFO) basis. Most importantly queues are thread-safe meaning that only one process can access the queue at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = multiprocessing.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.queues.Queue at 0x7f06f013c630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue.put(\"hello\")\n",
    "queue.put(\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'world'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 9056received: 0\n",
      "Process 9056received: 2Process 9057received: 1\n",
      "Process 9066received: 3\n",
      "\n",
      "Process 9056received: 6Process 9071received: 4Process 9057received: 5\n",
      "\n",
      "Process 9066received: 7\n",
      "Process 9057received: 8Process 9071received: 9\n",
      "\n",
      "Process 9066received: 10\n",
      "Process 9057received: 11\n",
      "\n",
      "Process 9071received: 12Process 9066received: 13Process 9057received: 14\n",
      "\n",
      "Process 9071received: 15\n",
      "Process 9066received: 16\n",
      "Process 9057received: 17Process 9071received: 18\n",
      "\n",
      "\n",
      "Process 9056received: 19\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "def worker(queue):\n",
    "    while not queue.empty():\n",
    "        print(\"Process \"+str(os.getpid())+\"received: \" + str(queue.get()))\n",
    "    \n",
    "\n",
    "    \n",
    "queue = multiprocessing.Queue()\n",
    "\n",
    "for i in range(20):\n",
    "    queue.put(i)\n",
    "num_processes=4\n",
    "processes=[]\n",
    "for _ in range(num_processes):\n",
    "    p=multiprocessing.Process(target=worker, args=[queue])\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "\n",
    "\n",
    "for pr in processes:\n",
    "    pr.join()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process pools\n",
    "### Similar to threadpools we can use process pools with exactl the same user case as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0Processing 3Processing 1Processing 2\n",
      "\n",
      "\n",
      "\n",
      "Processing 4Processing 6Processing 7\n",
      "Processing 8\n",
      "Processing 9\n",
      "\n",
      "Processing 10\n",
      "Processing 11\n",
      "Processing 12\n",
      "\n",
      "Processing 14Processing 13Processing 15\n",
      "Processing 5\n",
      "Processing 16\n",
      "Processing 17\n",
      "\n",
      "\n",
      "Processing 18\n",
      "Processing 19\n",
      "My result list [2, 0, 3, 1, 4, 6, 7, 8, 9, 10, 11, 12, 14, 13, 5, 16, 17, 15, 18, 19]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "def task(n):\n",
    "    print(\"Processing {}\".format(n))\n",
    "    return n\n",
    "\n",
    "number_of_threads=4\n",
    "pool = ProcessPoolExecutor(number_of_threads)\n",
    "\n",
    "\n",
    "futures=[]\n",
    "### We sumbit to the Threadpool all the tasks we want to perform\n",
    "for i in range(20): \n",
    "    futures.append(pool.submit(task,i)) #Syntax is pool.submit(function,args)\n",
    "results=[]\n",
    "\n",
    "###As threads are completed we collect the results\n",
    "for F in concurrent.futures.as_completed(futures):\n",
    "    results.append(F.result())\n",
    "    \n",
    "\n",
    "pool.shutdown(wait=True)\n",
    "print(\"My result list\",results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi processing and random numbers\n",
    "\n",
    "### One needs to be careful with random number generation and multi processing, as we could be using the same random number twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.408061032115131\n",
      "0.408061032115131\n",
      "0.408061032115131\n",
      "0.408061032115131\n",
      "0.6096351815323336\n",
      "0.5753350473409706\n",
      "0.6096351815323336\n",
      "0.6096351815323336\n",
      "0.6096351815323336\n",
      "0.9928851053867359\n",
      "0.5753350473409706\n",
      "0.5753350473409706\n",
      "0.5753350473409706\n",
      "0.6811398943987135\n",
      "0.9928851053867359\n",
      "0.4997081962297416\n",
      "0.9928851053867359\n",
      "0.6296222884818174\n",
      "0.9928851053867359\n",
      "0.6811398943987135\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "number_of_threads=4\n",
    "pool = ProcessPoolExecutor(number_of_threads)\n",
    "\n",
    "def Foo_np(seed=None):\n",
    "    return np.random.uniform(0, 1)\n",
    "\n",
    "results=pool.map(Foo_np, range(20))\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One needs to provide the random seed explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5488135]\n",
      "[0.417022]\n",
      "[0.4359949]\n",
      "[0.5507979]\n",
      "[0.96702984]\n",
      "[0.22199317]\n",
      "[0.89286015]\n",
      "[0.07630829]\n",
      "[0.8734294]\n",
      "[0.01037415]\n",
      "[0.77132064]\n",
      "[0.18026969]\n",
      "[0.15416284]\n",
      "[0.77770241]\n",
      "[0.51394334]\n",
      "[0.8488177]\n",
      "[0.22329108]\n",
      "[0.294665]\n",
      "[0.65037424]\n",
      "[0.0975336]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "number_of_threads=4\n",
    "pool = ProcessPoolExecutor(number_of_threads)\n",
    "\n",
    "def Foo_np(seed=None):\n",
    "    np.random.seed(seed)\n",
    "    return np.random.uniform(0, 1, 1)\n",
    "\n",
    "results=pool.map(Foo_np, range(20))\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple Monte Carlo example: computing Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pi_python(num_sim,seed):\n",
    "    np.random.seed(seed)\n",
    "    x=2.0*(np.random.random(size=num_sim)-0.5)# np.random.random returns U[0,1] so we reescale it to U[-1,1]\n",
    "    y=2.0*(np.random.random(size=num_sim)-0.5)\n",
    "\n",
    "    inside=np.sum(x*x+y*y<=1)\n",
    "    \n",
    "    \n",
    "    pi=inside/num_sim*4\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sim=10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441 ms ± 125 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit compute_pi_python(num_sim,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.14129"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_pi_python(num_sim,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "number_of_threads=4 \n",
    "def parallel_compute_pi_python(number_of_threads,num_sim):\n",
    "    pool = ProcessPoolExecutor(number_of_threads)\n",
    "\n",
    "\n",
    "    results=pool.map(compute_pi_python,[int(num_sim/number_of_threads)]*number_of_threads, range(number_of_threads))\n",
    "    MC_mean=0\n",
    "    for result in results:\n",
    "        MC_mean+=result\n",
    "    return MC_mean/number_of_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1413320000000002"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_compute_pi_python(4,num_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 8.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit parallel_compute_pi_python(4,num_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark 1: For multithreading to start to be noticeable the Monte Carlo simulation needs to be heavy as setting up the process pool adds overhead\n",
    "\n",
    "### Remark 2: We have made the oversimplication of changing the random seed arbitrarily in each process. This could cause that a sequence of random variables could be repeated accross processes and generate correlation. For the single process and multi-process approach to agree on the estimate one would need to set the correct seed on each process. This topic is outside the scope of this course, but one needs to be very careful with this!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
